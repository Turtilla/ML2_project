{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fbef038",
   "metadata": {},
   "source": [
    "# SHAKESPEAREAN PRONOUN TAGGER  \n",
    "A project by Maria Irena Szawerna for Machine learning for statistical NLP: Advanced LT2326 at the University of Gothenburg.  \n",
    "\n",
    "The aim of this project is testing whether it is possible to build a tagger for \"you\" pronouns in Shakespeare's works (whether they are singular, plural, or unknown) using modern tools (BERT embeddings and LSTM models) and annotated plays (\"Hamlet\" and \"As You Like It\") as the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a476a",
   "metadata": {},
   "source": [
    "### IMPORTING THE NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83971fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 14:31:43.611383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-14 14:31:43.611436: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertModel\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7afbe",
   "metadata": {},
   "source": [
    "### DATA-PROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59d6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the files the data will be sourced from\n",
    "shakespeare_plays = [\"trimmed-hamlet.txt\", \"trimmed-as-you-like-it.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bd6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_you_sents(filename, double=False):\n",
    "# this function is intended for opening a file with trimmed (character names and didaskalia removed), annotated play data; it\n",
    "# takes as an argument the name of the file and returns a list of sentences from the file that include any form of a \"you\" \n",
    "# pronoun, with all newline, tabs, and other such stuff removed.\n",
    "    with open(filename) as f: \n",
    "        # reading from the file\n",
    "        text = f.read()\n",
    "        # splitting the text into sentences using NLTK's sentence tokenizer\n",
    "        sents = sent_tokenize(text)\n",
    "        # the sentences provided by NLTK still have newline characters in them, inside the lines (as they come from a play, \n",
    "        # not a book) which need to be removed\n",
    "        # we also only need the sentences with \"you\" pronouns, and an option to only pick out sentences with one such pronoun\n",
    "        # present.\n",
    "    double_sents = []  # for more than one occurrence of \"you\"\n",
    "    single_sents = []  # for exactly one occurrence of \"you\"\n",
    "    for sent in sents:\n",
    "        tracker = 0  # to track how many \"you\" forms there are in the sentence\n",
    "        for element in word_tokenize(sent):\n",
    "            if '_SG' in element or '_PL' in element or '_UNK' in element:\n",
    "                tracker += 1\n",
    "        if tracker > 1:\n",
    "            double_sents.append(sent.replace('\\n', ' ').replace('\\t', '').replace('\\\\', ''))\n",
    "        elif tracker == 1:\n",
    "            single_sents.append(sent.replace('\\n', ' ').replace('\\t', '').replace('\\\\', ''))\n",
    "        else:  # if there are no \"you\" forms\n",
    "            continue\n",
    "    \n",
    "    # deciding which sentences will be returned by the function, the ones with only one \"you\" or also the ones with\n",
    "    # multiple ones\n",
    "    if double == False:\n",
    "        you_sents = single_sents\n",
    "    else:\n",
    "        you_sents = single_sents + double_sents\n",
    "\n",
    "    return you_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4cba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_files(file_list, double=False):\n",
    "# this function allows for obtaining you-sentences from many files simultaneously\n",
    "    all_sents = []\n",
    "    for filename in file_list:\n",
    "        file_sents = extract_you_sents(filename, double=double)\n",
    "        all_sents += file_sents\n",
    "    \n",
    "    return all_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284f8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(sentence_list, tokenizer):\n",
    "    # this function takes in a list of sentences with \"you\" pronoun(s) in them and creates samples of the shape (tokenized_sent,\n",
    "    # class, pronoun_index, sentence_length)\n",
    "    # the \"you\" pronouns are defined as the following variants: you -> [ye] [your] [yours] [yourself] [yourselves], as used\n",
    "    # in the original study in the corpus analysis software AntConc\n",
    "    # maximum_length is set to 200 as this is a bit above what the longest sentence is in this dataset; however, since we are\n",
    "    # not feeding this to the tokenizer in batches, we cannot just pad \n",
    "    prons = ['you', 'ye', 'your', 'yours', 'yourself', 'yourselves']  # all the \"you\" forms\n",
    "    converted_prons = tokenizer.convert_tokens_to_ids(prons)\n",
    "    conv_underscore = tokenizer.convert_tokens_to_ids('_')\n",
    "    \n",
    "    all_samples = []\n",
    "    for sent in sentence_list:\n",
    "        sent_cls = []\n",
    "        tokenized = tokenizer(sent)  # tokenizing the sentence using BERT tokenizer\n",
    "        for i in range(0, len(tokenized['input_ids'])):\n",
    "            # iterating through the tokenized sentence to find all the classes\n",
    "            if tokenized['input_ids'][i] == conv_underscore:\n",
    "                cls = tokenizer.convert_ids_to_tokens(tokenized['input_ids'][i+1])\n",
    "                sent_cls.append(cls)\n",
    "\n",
    "        # removing the annotation (as now we have that information ordered in sent_clss)\n",
    "        new_sent = sent.replace('_SG', '').replace('_PL', '').replace('_UNK', '')\n",
    "        \n",
    "        # creating and appending a sample for each \"you\" pronoun in the sentence; it is necessary to use the tokenizer on\n",
    "        # it to retrieve the appropriate index (and this is important as we have samples where there may be more than one\n",
    "        # \"you\" token); we do not save the tokenized sentence as we actually want those to be padded to the length of the\n",
    "        # longest sentence in the batch, which is also why we are saving the length here\n",
    "        full_sent = tokenizer(new_sent)\n",
    "        for i in range(0, len(full_sent['input_ids'])):\n",
    "            if full_sent['input_ids'][i] in converted_prons:\n",
    "                cls = sent_cls.pop(0)\n",
    "                idx = i  \n",
    "                all_samples.append([new_sent, cls, idx])\n",
    "    \n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b99d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_splits(samples, train_split=0.8, test_split=0.2, equalize=True):\n",
    "    # creating a function to mix and split the data stored in a list according to parameters introduced by the user\n",
    "    # avoiding potential errors\n",
    "    if (train_split + test_split) != 1:\n",
    "        print('Invalid data split proportions!')\n",
    "        return\n",
    "    \n",
    "    if equalize == False:\n",
    "        random.shuffle(samples)  # shuffling the data \n",
    "        test_size = math.ceil(len(samples) * test_split)  # deciding the point at which to split the samples\n",
    "        test_samples = samples[:test_size]\n",
    "        train_samples = samples[test_size:]\n",
    "    \n",
    "    # implementing \"equalizing\" so that all classes are equally represented, removing UNK as that one is significantly smaller\n",
    "    # than the other classes, effectively turning this into a binary classification problem\n",
    "    else:\n",
    "        sg_samples = []\n",
    "        pl_samples = []\n",
    "        for sample in samples:\n",
    "            if sample[1] == 'sg':\n",
    "                sg_samples.append(sample)\n",
    "            elif sample[1] == 'pl':\n",
    "                pl_samples.append(sample)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        if len(sg_samples) > len(pl_samples):\n",
    "            max_len = len(pl_samples)\n",
    "        else:\n",
    "            max_len = len(sg_samples)\n",
    "        \n",
    "        test_size = math.ceil(max_len * test_split)\n",
    "            \n",
    "        random.shuffle(sg_samples)\n",
    "        random.shuffle(pl_samples)\n",
    "        \n",
    "        selected_sg = sg_samples[:max_len]\n",
    "        selected_pl = pl_samples[:max_len]\n",
    "        \n",
    "        test_sg = selected_sg[:test_size]\n",
    "        train_sg = selected_sg[test_size:]\n",
    "        \n",
    "        test_pl = selected_pl[:test_size]\n",
    "        train_pl = selected_pl[test_size:]\n",
    "        \n",
    "        test_samples = test_sg + test_pl\n",
    "        train_samples = train_sg + train_pl\n",
    "        \n",
    "        random.shuffle(test_samples)\n",
    "        random.shuffle(train_samples)\n",
    "    \n",
    "    return train_samples, test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d5840",
   "metadata": {},
   "source": [
    "### DATA-ENCODING AND BATCHING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fb3b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT is imported and set in eval mode so that we can retrieve embeddings from it\n",
    "bert_model = BertModel.from_pretrained(model_name, return_dict=True, output_hidden_states=True)\n",
    "bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339a6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(input_ids, attention_mask, bert_device):\n",
    "    # a function to retrieve the word embeddings from BERT, required BERT to be initialized as bert_model beforehand and put\n",
    "    # in eval mode (see above), all of that with return_hidden_states=True\n",
    "    # inspired by https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#3-extracting-embeddings\n",
    "    # the same function was used in my Assignment 1 for this course\n",
    "    with torch.no_grad():\n",
    "        # getting the parts of the batch that are relevant\n",
    "        bert_model.to(bert_device)\n",
    "        output = bert_model(input_ids, attention_mask)\n",
    "        # hidden states for every layer are stored here\n",
    "        hidden_states = output[2]\n",
    "        # there are 13 elements in the hidden states, meaning the initial embeddings and hidden states from 12 layers;\n",
    "        # according to the link I provided above, there are mant approaches for what elements of these to use as word\n",
    "        # embeddings; I will use the second-to-last hidden layer\n",
    "        penultimate_layer = hidden_states[11]\n",
    "        # the penultimate layer now has the shape of batch * max_len of the sentence * 768 (BERT embedding size)\n",
    "    return penultimate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23e83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareCollate():\n",
    "    # custom collate class that processes the data from the batched list of samples as they are accessed \n",
    "    def __init__(self, tokenizer, device, bert_device):\n",
    "        # defining the tokenizer and the devices on which BERT and the actual model will run\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.bert_device = bert_device\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        # performing the necessary operations on every batch\n",
    "        sentences = []\n",
    "        classes = []\n",
    "        indices = []\n",
    "        \n",
    "        for element in batch:\n",
    "            sentences.append(element[0]) \n",
    "            classes.append(element[1])\n",
    "            indices.append(torch.tensor([element[2]]))\n",
    "        \n",
    "        # one-hot encoding classes    \n",
    "        for i in range(0, len(classes)):\n",
    "            if classes[i] == 'sg':\n",
    "                classes[i] = torch.FloatTensor([1])\n",
    "            elif classes[i] == 'pl':\n",
    "                classes[i] = torch.FloatTensor([0])\n",
    "\n",
    "        # calling the BERT tokenizer on the sentences\n",
    "        tokens = self.tokenizer(sentences, \n",
    "                                            add_special_tokens=True, \n",
    "                                            return_tensors='pt',\n",
    "                                            padding=True, \n",
    "                                            return_attention_mask=True,\n",
    "                                            is_split_into_words=False)\n",
    "         \n",
    "        input_ids=tokens['input_ids'].to(self.bert_device)\n",
    "        attention_masks=tokens['attention_mask'].to(self.bert_device)\n",
    "        # calling the embeddings function since we want to feed the network the BERT embeddings; make sure that BERT is\n",
    "        # on the same device as the rest before that\n",
    "        # all of the output is moved to the model device, classes and indices are stacked since it has to be a tensor, \n",
    "        # not a list\n",
    "        bert_embeddings = get_embeddings(input_ids, attention_masks, self.bert_device).to(self.device)  \n",
    "        classes = torch.stack(classes).to(self.device)\n",
    "        indices = torch.stack(indices).to(self.device)\n",
    "        \n",
    "        return bert_embeddings, classes, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aebccc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shakespeare_dataloader(data, tokenizer, device, bert_device, batch_size=32, shuffle=True): \n",
    "    # little function to easily obtain dataloaders using our dataset and custom ShakespeareCollate class which does all the\n",
    "    # hard work of transforming sentences into BERT embedding representations, one-hot-encoding the classes and turning what\n",
    "    # is needed to be turned into tensors.\n",
    "    loader = DataLoader(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=True,\n",
    "        collate_fn=ShakespeareCollate(tokenizer, device, bert_device) )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe48fc5",
   "metadata": {},
   "source": [
    "### TRAINING LOOP AND MODEL SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efdc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareanClassifier(nn.Module):\n",
    "    # class of the model itself; \n",
    "    def __init__(self, hidden_size):\n",
    "        super(ShakespeareanClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = 1  # for the binary classification 0/1\n",
    "        self.embedding_dim = 768  # BERT embedding size\n",
    "\n",
    "\n",
    "        # the text processing layer is a bidirectional LSTM; the input size here is the size of BERT embeddings, the hidden\n",
    "        # size is set by the user; it is a bidirectional LSTM \n",
    "        self.LSTM = nn.LSTM(\n",
    "                            input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_size, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True, \n",
    "                            bidirectional=True\n",
    "                            )\n",
    "        \n",
    "        self.classification = nn.Sequential( \n",
    "                            nn.Dropout(0.05),\n",
    "                            nn.Linear(self.hidden_size*2, self.hidden_size),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Linear(self.hidden_size, self.output_dim),\n",
    "                            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, bert_embeddings, indices, device):\n",
    "        # for calling the model we need to input the BERT embeddings from the batch \n",
    "        converted_embeddings = bert_embeddings.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        # the captions are fed through the LSTM, and the hidden state at the index of the pronoun is saved, as per the \n",
    "        # documentation \"When bidirectional=True, output will contain a concatenation of the forward and reverse hidden \n",
    "        # states at each time step in the sequence.\" (https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html), so\n",
    "        # I do not need to concatenate anything myself and selecting an indexed timestep representation already gives\n",
    "        # me something that a) is double the size of the hidden layer b) contains information from both directions\n",
    "        timestep_representation, (final_hidden, final_cell) = self.LSTM(converted_embeddings)\n",
    "        processed_embeddings = torch.stack([tp[i] for i, tp in zip(indices, timestep_representation)])\n",
    "        # the data is fed to the classification layer\n",
    "        output = self.classification(processed_embeddings)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962e53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params, train_samples):\n",
    "    # this function is intended for training an instance of the ShakespeareanClassifier\n",
    "    model.to(params['device'])\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "    for epoch in range(1,params['epochs']+1):  # so that it prints out nicely\n",
    "    \n",
    "        train_iter = shakespeare_dataloader(\n",
    "            train_samples, tokenizer, params['device'], params['bert_device'], batch_size=params['batch_size'], shuffle=True\n",
    "        )\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_iter):\n",
    "\n",
    "            if True:  # i < 20: For testing\n",
    "                sentences = batch[0]\n",
    "                classes = batch[1]\n",
    "                indices = batch[2]\n",
    "\n",
    "                # send your batch of sentences to the model\n",
    "                output = model(sentences, indices, params['device'])\n",
    "                \n",
    "                loss = loss_function(torch.squeeze(output, dim=1), classes)  # output is squeezed to fit the original classes\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                if i%5==0:\n",
    "                    print(f' Batch {i} : Average Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "\n",
    "                # calculate gradients\n",
    "                loss.backward()\n",
    "                # update model weights\n",
    "                optimizer.step()\n",
    "                # reset gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        print(f'Epoch {epoch} : Average Training Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "775e02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(item, file_name):\n",
    "    # a small function intended to be used to save a trained model\n",
    "    pickle.dump(item, open(file_name, 'wb'))\n",
    "\n",
    "def load(file_name):\n",
    "    # a small function intended to be used to load a trained model\n",
    "    item = pickle.load(open(file_name, 'rb'))\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcaacc3",
   "metadata": {},
   "source": [
    "### TESTING AND EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb74dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, params, test_samples):\n",
    "    model.to(params['device'])\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_classes = []\n",
    "    with torch.no_grad():\n",
    "        test_iter = shakespeare_dataloader(\n",
    "            test_samples, tokenizer, params['device'], params['bert_device'], batch_size=params['batch_size'], shuffle=False\n",
    "        )    \n",
    "        for j, batch in enumerate(test_iter):\n",
    "            sentences = batch[0]\n",
    "            indices = batch[2]\n",
    "\n",
    "            o = model(sentences, indices, params['device'])\n",
    "            predictions = torch.squeeze(o).tolist()  # making sure that we get predictions in the correct format\n",
    "            # encoding the predictions to reflect not probabilities, but classes; \n",
    "            for i in range(0, len(predictions)):\n",
    "                if predictions[i] > 0.5:\n",
    "                    predictions[i] = 1.0\n",
    "                else:\n",
    "                    predictions[i] = 0.0\n",
    "            all_predictions += predictions\n",
    "            all_classes += torch.squeeze(batch[1]).tolist()\n",
    "\n",
    "    print('Testing complete!')\n",
    "\n",
    "    return all_predictions, all_classes              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9b60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(predicted_classes, true_classes):\n",
    "    # this function goes over the output of the testing function and provides some basic evaluation measures, such as\n",
    "    # accuracy, recall, precision, and f1, using sklearn's functions (although I did manually implement it in assignment 1)\n",
    "    print('The following measures have been recorded for this model:')\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(true_classes, predicted_classes)\n",
    "    recall = sklearn.metrics.recall_score(true_classes, predicted_classes)\n",
    "    precision = sklearn.metrics.precision_score(true_classes, predicted_classes)\n",
    "    f1 = sklearn.metrics.f1_score(true_classes, predicted_classes)\n",
    "    \n",
    "    print(f'\\tAccuracy = {accuracy}')\n",
    "    print(f'\\tRecall = {recall}')\n",
    "    print(f'\\tPrecision = {precision}')\n",
    "    print(f'\\tF1 = {f1}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "760c5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(predicted_classes, test_samples):\n",
    "    # a function for easy making of a dataframe to display the results together with the sentences\n",
    "    rows = []\n",
    "    for i in range(0, len(predicted_classes)):\n",
    "        prediction = predicted_classes[i]\n",
    "        if prediction == 1.0:\n",
    "            prediction = 'sg'\n",
    "        else:\n",
    "            prediction = 'pl'\n",
    "        truth = test_samples[i][1]\n",
    "        sentence = test_samples[i][0]\n",
    "        rows.append([sentence, prediction, truth])\n",
    "\n",
    "    model_df = pd.DataFrame(rows)\n",
    "    model_df.columns = [\"sentence\", \"predicted class\", \"true class\"]\n",
    "\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bccabd",
   "metadata": {},
   "source": [
    "### RUNNING THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "689c9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "you_sents = extract_from_files(shakespeare_plays, double=True)\n",
    "samples = create_samples(you_sents, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d018b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, test_samples = samples_splits(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0a9a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 0 : Average Loss = 0.69195\n",
      " Batch 5 : Average Loss = 0.69831\n",
      " Batch 10 : Average Loss = 0.69283\n",
      " Batch 15 : Average Loss = 0.69293\n",
      " Batch 20 : Average Loss = 0.69126\n",
      " Batch 25 : Average Loss = 0.68737\n",
      " Batch 30 : Average Loss = 0.68694\n",
      " Batch 35 : Average Loss = 0.68124\n",
      " Batch 40 : Average Loss = 0.67536\n",
      "Epoch 1 : Average Training Loss = 0.6762\n",
      " Batch 0 : Average Loss = 0.62853\n",
      " Batch 5 : Average Loss = 0.60205\n",
      " Batch 10 : Average Loss = 0.60413\n",
      " Batch 15 : Average Loss = 0.60285\n",
      " Batch 20 : Average Loss = 0.60084\n",
      " Batch 25 : Average Loss = 0.59885\n",
      " Batch 30 : Average Loss = 0.59939\n",
      " Batch 35 : Average Loss = 0.58433\n",
      " Batch 40 : Average Loss = 0.58173\n",
      "Epoch 2 : Average Training Loss = 0.57901\n",
      " Batch 0 : Average Loss = 0.31875\n",
      " Batch 5 : Average Loss = 0.46795\n",
      " Batch 10 : Average Loss = 0.50825\n",
      " Batch 15 : Average Loss = 0.49186\n",
      " Batch 20 : Average Loss = 0.50175\n",
      " Batch 25 : Average Loss = 0.49693\n",
      " Batch 30 : Average Loss = 0.47629\n",
      " Batch 35 : Average Loss = 0.47858\n",
      " Batch 40 : Average Loss = 0.46664\n",
      "Epoch 3 : Average Training Loss = 0.46842\n",
      " Batch 0 : Average Loss = 0.34622\n",
      " Batch 5 : Average Loss = 0.34845\n",
      " Batch 10 : Average Loss = 0.38311\n",
      " Batch 15 : Average Loss = 0.37918\n",
      " Batch 20 : Average Loss = 0.36715\n",
      " Batch 25 : Average Loss = 0.35574\n",
      " Batch 30 : Average Loss = 0.34023\n",
      " Batch 35 : Average Loss = 0.35759\n",
      " Batch 40 : Average Loss = 0.34181\n",
      "Epoch 4 : Average Training Loss = 0.33624\n",
      " Batch 0 : Average Loss = 0.09254\n",
      " Batch 5 : Average Loss = 0.19204\n",
      " Batch 10 : Average Loss = 0.25634\n",
      " Batch 15 : Average Loss = 0.22048\n",
      " Batch 20 : Average Loss = 0.2101\n",
      " Batch 25 : Average Loss = 0.20774\n",
      " Batch 30 : Average Loss = 0.20589\n",
      " Batch 35 : Average Loss = 0.21858\n",
      " Batch 40 : Average Loss = 0.2245\n",
      "Epoch 5 : Average Training Loss = 0.2219\n"
     ]
    }
   ],
   "source": [
    "params = {'lr':0.00005, 'batch_size':8, 'hidden_size':1024, 'epochs':5, 'device':'cpu', 'bert_device':'cpu'} \n",
    "model = ShakespeareanClassifier(params['hidden_size'])\n",
    "trained_model = train(model, params, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "056abb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(trained_model, 'trained_model_full.pickle')\n",
    "save(test_samples, 'test_samples_full.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c476f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "predicted_classes, true_classes = test(trained_model, params, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c2dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following measures have been recorded for this model:\n",
      "\tAccuracy = 0.675\n",
      "\tRecall = 0.5853658536585366\n",
      "\tPrecision = 0.7272727272727273\n",
      "\tF1 = 0.6486486486486487\n"
     ]
    }
   ],
   "source": [
    "measures(predicted_classes, true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d8d8a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicted class</th>\n",
       "      <th>true class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What have you, my good friends, deserved at the hands of Fortune that she sends you to prison hither?</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That if you be honest and fair, your honesty should admit no discourse to your beauty.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>God hath given you one face, and you make yourselves another.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you advise me?</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you like upon report The soil, the profit, and this kind of life, I will your very faithful feeder be And buy it with your gold right suddenly.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I will requite your loves.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>All you gods In general synod take away her power, Break all the spokes and fellies from her wheel, And bowl the round nave down the hill of heaven As low as to the fiends!</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Then you live about her waist, or in the middle of her favors?</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You are the Queen, your husband's brother's wife, And (would it were not so) you are my mother.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Your loves, as mine to you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Do you not come your tardy son to chide, That, lapsed in time and passion, lets go by Th' important acting of your dread command?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yours.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>To this effect, sir, after what flourish your nature will.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This fellow will but join you together as they join wainscot.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Come on, you hear this fellow in the cellarage.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>If by direct or by collateral hand They find us touched, we will our kingdom give, Our crown, our life, and all that we call ours, To you in satisfaction; but if not, Be you content to lend your patience to us, And we shall jointly labor with your soul To give it due content.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>That great baby you see there is not yet out of his swaddling clouts.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O, that your Highness knew my heart in this: I never loved my brother in my life.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Moreover that we much did long to see you, The need we have to use you did provoke Our hasty sending.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What think you on 't?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Be not you ashamed to show, he'll not shame to tell you what it means.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>You must not put another scandal on him That he is open to incontinency; That's not my meaning.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Let me go with you.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>And you, the judges, bear a wary eye.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Fare you well.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>If that an eye may profit by a tongue, Then should I know you by description-- Such garments, and such years.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nay then, God be wi' you, an you talk in blank verse.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I your commission will forthwith dispatch, And he to England shall along with you.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>You could, for a need, study a speech of some dozen or sixteen lines, which I would set down and insert in 't, could you not?</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I pray you all, If you have hitherto concealed this sight, Let it be tenable in your silence still; And whatsomever else shall hap tonight, Give it an understanding but no tongue.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I will tell you the beginning, and if it please your Ladyships, you may see the end, for the best is yet to do, and here, where you are, they are coming to perform it.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I your commission will forthwith dispatch, And he to England shall along with you.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Let me comply with you in this garb, lest my extent to the players, which, I tell you, must show fairly outwards, should more appear like entertainment than yourselves.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>And I beseech you instantly to visit My too much changed son.--Go, some of you, And bring these gentlemen where Hamlet is.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>For Lord Hamlet, Believe so much in him that he is young, And with a larger tether may he walk Than may be given you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>You say that you 'll have Phoebe if she will?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Masters, you are all welcome.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>For us and for our tragedy, Here stooping to your clemency, We beg your hearing patiently.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I did love you once.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A king of shreds and patches--  Save me and hover o'er me with your wings, You heavenly guards!--What would your gracious figure?</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>My lord, you played once i' th' university, you say?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Even those you were wont to take such delight in, the tragedians of the city.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Therefore prepare you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>As you love Phoebe, meet.--And as I love no woman, I'll meet.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>You shall have some part of your will.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I must to England, you know that.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Then it will be the earliest fruit i' th' country, for you 'll be rotten ere you be half ripe, and that's the right virtue of the medlar.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>No, you will reveal it.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Nay, then I'll set those to you that can speak.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>I will not trouble you As yet to question you about your fortunes.-- Give us some music, and, good cousin, sing.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Then weigh what loss your honor may sustain If with too credent ear you list his songs Or lose your heart or your chaste treasure open To his unmastered importunity.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>You, laying these slight sullies on my son, As 'twere a thing a little soiled i' th' working, Mark you, your party in converse, him you would sound, Having ever seen in the prenominate crimes The youth you breathe of guilty, be assured He closes with you in this consequence: \"Good sir,\" or so, or \"friend,\" or \"gentleman,\" According to the phrase or the addition Of man and country--  Very good, my lord.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Pray you, if you know, Where in the purlieus of this forest stands A sheepcote fenced about with olive trees?</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>You were sent for, and there is a kind of confession in your looks which your modesties have not craft enough to color.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>'Tis told me he hath very oft of late Given private time to you, and you yourself Have of your audience been most free and bounteous.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>So fare you well.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>I do not fear it; I have seen you both.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Think yourself a baby That you have ta'en these tenders for true pay, Which are not sterling.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>I charge you, O women, for the love you bear to men, to like as much of this play as please you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>I'll be with you straight.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>I have of late, but wherefore I know not, lost all my mirth, forgone all custom of exercises, and, indeed, it goes so heavily with my disposition that this goodly frame, the Earth, seems to me a sterile promontory; this most excellent canopy, the air, look you, this brave o'erhanging firmament, this majestical roof, fretted with golden fire--why, it appeareth nothing to me but a foul and pestilent congregation of vapors.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>If you outstay the time, upon mine honor And in the greatness of my word, you die.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>If by direct or by collateral hand They find us touched, we will our kingdom give, Our crown, our life, and all that we call ours, To you in satisfaction; but if not, Be you content to lend your patience to us, And we shall jointly labor with your soul To give it due content.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>These blazes, daughter, Giving more light than heat, extinct in both Even in their promise as it is a-making, You must not take for fire.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>You jig and amble, and you lisp; you nickname God's creatures and make your wantonness your ignorance.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Be not you ashamed to show, he'll not shame to tell you what it means.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>But let me conjure you by the rights of our fellowship, by the consonancy of our youth, by the obligation of our ever-preserved love, and by what more dear a better proposer can charge you withal: be even and direct with me whether you were sent for or no.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>And wherefore are you gentle, strong, and valiant?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>O, this is counter, you false Danish dogs!</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>You are welcome to Elsinore.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>But whate'er you are That in this desert inaccessible, Under the shade of melancholy boughs, Lose and neglect the creeping hours of time, If ever you have looked on better days, If ever been where bells have knolled to church, If ever sat at any good man's feast, If ever from your eyelids wiped a tear And know what 'tis to pity and be pitied, Let gentleness my strong enforcement be, In the which hope I blush and hide my sword.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Something have you heard Of Hamlet's transformation, so call it, Sith nor th' exterior nor the inward man Resembles that it was.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Therefore put you in your best array, bid your friends; for if you will be married tomorrow, you shall, and to Rosalind, if you will.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>I will tell you the beginning, and if it please your Ladyships, you may see the end, for the best is yet to do, and here, where you are, they are coming to perform it.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>I am given, sir, secretly to understand that your younger brother Orlando hath a disposition to come in disguised against me to try a fall.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Down on your knees And thank heaven, fasting, for a good man's love, For I must tell you friendly in your ear, Sell when you can; you are not for all markets.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>I will name you the degrees: the first, \"the retort courteous\"; the second, \"the quip modest\"; the third, \"the reply churlish\"; the fourth, \"the reproof valiant\"; the fifth, \"the countercheck quarrelsome\"; the sixth, \"the lie with circumstance\"; the seventh, \"the lie direct.\"</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Yonder comes my master, your brother.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>But let your fair eyes and gentle wishes go with me to my trial, wherein, if I be foiled, there is but one shamed that was never gracious; if killed, but one dead that is willing to be so.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>I entreat you both That, being of so young days brought up with him And sith so neighbored to his youth and havior, That you vouchsafe your rest here in our court Some little time, so by your companies To draw him on to pleasures, and to gather So much as from occasion you may glean, Whether aught to us unknown afflicts him thus That, opened, lies within our remedy.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                          sentence  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                            What have you, my good friends, deserved at the hands of Fortune that she sends you to prison hither?   \n",
       "1                                                                                                                                                                                                                                                                                                                                                           That if you be honest and fair, your honesty should admit no discourse to your beauty.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                    God hath given you one face, and you make yourselves another.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                               Can you advise me?   \n",
       "4                                                                                                                                                                                                                                                                                               If you like upon report The soil, the profit, and this kind of life, I will your very faithful feeder be And buy it with your gold right suddenly.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                       I will requite your loves.   \n",
       "6                                                                                                                                                                                                                                                                     All you gods In general synod take away her power, Break all the spokes and fellies from her wheel, And bowl the round nave down the hill of heaven As low as to the fiends!   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                   Then you live about her waist, or in the middle of her favors?   \n",
       "8                                                                                                                                                                                                                                                                                                                                                  You are the Queen, your husband's brother's wife, And (would it were not so) you are my mother.   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                      Your loves, as mine to you.   \n",
       "10                                                                                                                                                                                                                                                                                                               Do you not come your tardy son to chide, That, lapsed in time and passion, lets go by Th' important acting of your dread command?   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                          Yours.   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                      To this effect, sir, after what flourish your nature will.   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                   This fellow will but join you together as they join wainscot.   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                 Come on, you hear this fellow in the cellarage.   \n",
       "15                                                                                                                                                            If by direct or by collateral hand They find us touched, we will our kingdom give, Our crown, our life, and all that we call ours, To you in satisfaction; but if not, Be you content to lend your patience to us, And we shall jointly labor with your soul To give it due content.   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                           That great baby you see there is not yet out of his swaddling clouts.   \n",
       "17                                                                                                                                                                                                                                                                                                                                                               O, that your Highness knew my heart in this: I never loved my brother in my life.   \n",
       "18                                                                                                                                                                                                                                                                                                                                           Moreover that we much did long to see you, The need we have to use you did provoke Our hasty sending.   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                           What think you on 't?   \n",
       "20                                                                                                                                                                                                                                                                                                                                                                          Be not you ashamed to show, he'll not shame to tell you what it means.   \n",
       "21                                                                                                                                                                                                                                                                                                                                                 You must not put another scandal on him That he is open to incontinency; That's not my meaning.   \n",
       "22                                                                                                                                                                                                                                                                                                                                                                                                                             Let me go with you.   \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                           And you, the judges, bear a wary eye.   \n",
       "24                                                                                                                                                                                                                                                                                                                                                                                                                                  Fare you well.   \n",
       "25                                                                                                                                                                                                                                                                                                                                   If that an eye may profit by a tongue, Then should I know you by description-- Such garments, and such years.   \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                           Nay then, God be wi' you, an you talk in blank verse.   \n",
       "27                                                                                                                                                                                                                                                                                                                                                              I your commission will forthwith dispatch, And he to England shall along with you.   \n",
       "28                                                                                                                                                                                                                                                                                                                   You could, for a need, study a speech of some dozen or sixteen lines, which I would set down and insert in 't, could you not?   \n",
       "29                                                                                                                                                                                                                                                             I pray you all, If you have hitherto concealed this sight, Let it be tenable in your silence still; And whatsomever else shall hap tonight, Give it an understanding but no tongue.   \n",
       "30                                                                                                                                                                                                                                                                         I will tell you the beginning, and if it please your Ladyships, you may see the end, for the best is yet to do, and here, where you are, they are coming to perform it.   \n",
       "31                                                                                                                                                                                                                                                                                                                                                              I your commission will forthwith dispatch, And he to England shall along with you.   \n",
       "32                                                                                                                                                                                                                                                                        Let me comply with you in this garb, lest my extent to the players, which, I tell you, must show fairly outwards, should more appear like entertainment than yourselves.   \n",
       "33                                                                                                                                                                                                                                                                                                                      And I beseech you instantly to visit My too much changed son.--Go, some of you, And bring these gentlemen where Hamlet is.   \n",
       "34                                                                                                                                                                                                                                                                                                                           For Lord Hamlet, Believe so much in him that he is young, And with a larger tether may he walk Than may be given you.   \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                                   You say that you 'll have Phoebe if she will?   \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                   Masters, you are all welcome.   \n",
       "37                                                                                                                                                                                                                                                                                                                                                      For us and for our tragedy, Here stooping to your clemency, We beg your hearing patiently.   \n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                            I did love you once.   \n",
       "39                                                                                                                                                                                                                                                                                                               A king of shreds and patches--  Save me and hover o'er me with your wings, You heavenly guards!--What would your gracious figure?   \n",
       "40                                                                                                                                                                                                                                                                                                                                                                                            My lord, you played once i' th' university, you say?   \n",
       "41                                                                                                                                                                                                                                                                                                                                                                   Even those you were wont to take such delight in, the tragedians of the city.   \n",
       "42                                                                                                                                                                                                                                                                                                                                                                                                                          Therefore prepare you.   \n",
       "43                                                                                                                                                                                                                                                                                                                                                                                   As you love Phoebe, meet.--And as I love no woman, I'll meet.   \n",
       "44                                                                                                                                                                                                                                                                                                                                                                                                          You shall have some part of your will.   \n",
       "45                                                                                                                                                                                                                                                                                                                                                                                                               I must to England, you know that.   \n",
       "46                                                                                                                                                                                                                                                                                                       Then it will be the earliest fruit i' th' country, for you 'll be rotten ere you be half ripe, and that's the right virtue of the medlar.   \n",
       "47                                                                                                                                                                                                                                                                                                                                                                                                                         No, you will reveal it.   \n",
       "48                                                                                                                                                                                                                                                                                                                                                                                                 Nay, then I'll set those to you that can speak.   \n",
       "49                                                                                                                                                                                                                                                                                                                                I will not trouble you As yet to question you about your fortunes.-- Give us some music, and, good cousin, sing.   \n",
       "50                                                                                                                                                                                                                                                                           Then weigh what loss your honor may sustain If with too credent ear you list his songs Or lose your heart or your chaste treasure open To his unmastered importunity.   \n",
       "51                           You, laying these slight sullies on my son, As 'twere a thing a little soiled i' th' working, Mark you, your party in converse, him you would sound, Having ever seen in the prenominate crimes The youth you breathe of guilty, be assured He closes with you in this consequence: \"Good sir,\" or so, or \"friend,\" or \"gentleman,\" According to the phrase or the addition Of man and country--  Very good, my lord.   \n",
       "52                                                                                                                                                                                                                                                                                                                                   Pray you, if you know, Where in the purlieus of this forest stands A sheepcote fenced about with olive trees?   \n",
       "53                                                                                                                                                                                                                                                                                                                         You were sent for, and there is a kind of confession in your looks which your modesties have not craft enough to color.   \n",
       "54                                                                                                                                                                                                                                                                                                           'Tis told me he hath very oft of late Given private time to you, and you yourself Have of your audience been most free and bounteous.   \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                               So fare you well.   \n",
       "56                                                                                                                                                                                                                                                                                                                                                                                                         I do not fear it; I have seen you both.   \n",
       "57                                                                                                                                                                                                                                                                                                                                                   Think yourself a baby That you have ta'en these tenders for true pay, Which are not sterling.   \n",
       "58                                                                                                                                                                                                                                                                                                                                                I charge you, O women, for the love you bear to men, to like as much of this play as please you.   \n",
       "59                                                                                                                                                                                                                                                                                                                                                                                                                      I'll be with you straight.   \n",
       "60        I have of late, but wherefore I know not, lost all my mirth, forgone all custom of exercises, and, indeed, it goes so heavily with my disposition that this goodly frame, the Earth, seems to me a sterile promontory; this most excellent canopy, the air, look you, this brave o'erhanging firmament, this majestical roof, fretted with golden fire--why, it appeareth nothing to me but a foul and pestilent congregation of vapors.   \n",
       "61                                                                                                                                                                                                                                                                                                                                                              If you outstay the time, upon mine honor And in the greatness of my word, you die.   \n",
       "62                                                                                                                                                            If by direct or by collateral hand They find us touched, we will our kingdom give, Our crown, our life, and all that we call ours, To you in satisfaction; but if not, Be you content to lend your patience to us, And we shall jointly labor with your soul To give it due content.   \n",
       "63                                                                                                                                                                                                                                                                                                       These blazes, daughter, Giving more light than heat, extinct in both Even in their promise as it is a-making, You must not take for fire.   \n",
       "64                                                                                                                                                                                                                                                                                                                                          You jig and amble, and you lisp; you nickname God's creatures and make your wantonness your ignorance.   \n",
       "65                                                                                                                                                                                                                                                                                                                                                                          Be not you ashamed to show, he'll not shame to tell you what it means.   \n",
       "66                                                                                                                                                                                But let me conjure you by the rights of our fellowship, by the consonancy of our youth, by the obligation of our ever-preserved love, and by what more dear a better proposer can charge you withal: be even and direct with me whether you were sent for or no.   \n",
       "67                                                                                                                                                                                                                                                                                                                                                                                              And wherefore are you gentle, strong, and valiant?   \n",
       "68                                                                                                                                                                                                                                                                                                                                                                                                      O, this is counter, you false Danish dogs!   \n",
       "69                                                                                                                                                                                                                                                                                                                                                                                                                    You are welcome to Elsinore.   \n",
       "70  But whate'er you are That in this desert inaccessible, Under the shade of melancholy boughs, Lose and neglect the creeping hours of time, If ever you have looked on better days, If ever been where bells have knolled to church, If ever sat at any good man's feast, If ever from your eyelids wiped a tear And know what 'tis to pity and be pitied, Let gentleness my strong enforcement be, In the which hope I blush and hide my sword.   \n",
       "71                                                                                                                                                                                                                                                                                                                Something have you heard Of Hamlet's transformation, so call it, Sith nor th' exterior nor the inward man Resembles that it was.   \n",
       "72                                                                                                                                                                                                                                                                                                           Therefore put you in your best array, bid your friends; for if you will be married tomorrow, you shall, and to Rosalind, if you will.   \n",
       "73                                                                                                                                                                                                                                                                         I will tell you the beginning, and if it please your Ladyships, you may see the end, for the best is yet to do, and here, where you are, they are coming to perform it.   \n",
       "74                                                                                                                                                                                                                                                                                                     I am given, sir, secretly to understand that your younger brother Orlando hath a disposition to come in disguised against me to try a fall.   \n",
       "75                                                                                                                                                                                                                                                                                  Down on your knees And thank heaven, fasting, for a good man's love, For I must tell you friendly in your ear, Sell when you can; you are not for all markets.   \n",
       "76                                                                                                                                                            I will name you the degrees: the first, \"the retort courteous\"; the second, \"the quip modest\"; the third, \"the reply churlish\"; the fourth, \"the reproof valiant\"; the fifth, \"the countercheck quarrelsome\"; the sixth, \"the lie with circumstance\"; the seventh, \"the lie direct.\"   \n",
       "77                                                                                                                                                                                                                                                                                                                                                                                                           Yonder comes my master, your brother.   \n",
       "78                                                                                                                                                                                                                                                    But let your fair eyes and gentle wishes go with me to my trial, wherein, if I be foiled, there is but one shamed that was never gracious; if killed, but one dead that is willing to be so.   \n",
       "79                                                                I entreat you both That, being of so young days brought up with him And sith so neighbored to his youth and havior, That you vouchsafe your rest here in our court Some little time, so by your companies To draw him on to pleasures, and to gather So much as from occasion you may glean, Whether aught to us unknown afflicts him thus That, opened, lies within our remedy.   \n",
       "\n",
       "   predicted class true class  \n",
       "0               pl         pl  \n",
       "1               sg         sg  \n",
       "2               pl         pl  \n",
       "3               pl         sg  \n",
       "4               sg         pl  \n",
       "5               pl         pl  \n",
       "6               pl         pl  \n",
       "7               sg         pl  \n",
       "8               sg         sg  \n",
       "9               pl         pl  \n",
       "10              sg         sg  \n",
       "11              pl         sg  \n",
       "12              sg         sg  \n",
       "13              pl         pl  \n",
       "14              sg         pl  \n",
       "15              pl         sg  \n",
       "16              pl         pl  \n",
       "17              sg         sg  \n",
       "18              pl         pl  \n",
       "19              sg         sg  \n",
       "20              pl         sg  \n",
       "21              sg         sg  \n",
       "22              sg         sg  \n",
       "23              pl         pl  \n",
       "24              pl         sg  \n",
       "25              pl         pl  \n",
       "26              sg         sg  \n",
       "27              sg         pl  \n",
       "28              pl         sg  \n",
       "29              pl         pl  \n",
       "30              sg         pl  \n",
       "31              sg         pl  \n",
       "32              pl         pl  \n",
       "33              pl         pl  \n",
       "34              pl         sg  \n",
       "35              sg         sg  \n",
       "36              pl         pl  \n",
       "37              pl         pl  \n",
       "38              sg         sg  \n",
       "39              pl         pl  \n",
       "40              sg         sg  \n",
       "41              sg         sg  \n",
       "42              pl         pl  \n",
       "43              sg         sg  \n",
       "44              sg         sg  \n",
       "45              sg         sg  \n",
       "46              sg         sg  \n",
       "47              sg         pl  \n",
       "48              pl         sg  \n",
       "49              pl         pl  \n",
       "50              sg         sg  \n",
       "51              pl         sg  \n",
       "52              pl         pl  \n",
       "53              pl         pl  \n",
       "54              sg         sg  \n",
       "55              pl         pl  \n",
       "56              pl         sg  \n",
       "57              sg         sg  \n",
       "58              pl         pl  \n",
       "59              pl         pl  \n",
       "60              sg         pl  \n",
       "61              pl         sg  \n",
       "62              pl         sg  \n",
       "63              pl         sg  \n",
       "64              pl         pl  \n",
       "65              sg         sg  \n",
       "66              pl         pl  \n",
       "67              sg         sg  \n",
       "68              sg         pl  \n",
       "69              pl         pl  \n",
       "70              pl         sg  \n",
       "71              pl         pl  \n",
       "72              sg         sg  \n",
       "73              pl         pl  \n",
       "74              pl         sg  \n",
       "75              pl         sg  \n",
       "76              pl         sg  \n",
       "77              sg         sg  \n",
       "78              pl         pl  \n",
       "79              pl         pl  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "model_df = make_dataframe(predicted_classes, test_samples)\n",
    "display(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221224f",
   "metadata": {},
   "source": [
    "### DONE UNTIL HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

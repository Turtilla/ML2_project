{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fbef038",
   "metadata": {},
   "source": [
    "# SHAKESPEAREAN PRONOUN TAGGER  \n",
    "A project by Maria Irena Szawerna for Machine learning for statistical NLP: Advanced LT2326 at the University of Gothenburg.  \n",
    "\n",
    "The aim of this project is testing whether it is possible to build a tagger for \"you\" pronouns in Shakespeare's works (whether they are singular, plural, or unknown) using modern tools (BERT embeddings and LSTM models) and annotated plays (\"Hamlet\" and \"As You Like It\") as the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a476a",
   "metadata": {},
   "source": [
    "### IMPORTING THE NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a404da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment once if running on mltgpu\n",
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83971fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertModel\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7afbe",
   "metadata": {},
   "source": [
    "### DATA-PROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59d6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the files the data will be sourced from\n",
    "shakespeare_plays = [\"trimmed-hamlet.txt\", \"trimmed-as-you-like-it.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bd6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_you_sents(filename, double=False):\n",
    "# this function is intended for opening a file with trimmed (character names and didaskalia removed), annotated play data; it\n",
    "# takes as an argument the name of the file and returns a list of sentences from the file that include any form of a \"you\" \n",
    "# pronoun, with all newline, tabs, and other such stuff removed.\n",
    "    with open(filename) as f: \n",
    "        # reading from the file\n",
    "        text = f.read()\n",
    "        # splitting the text into sentences using NLTK's sentence tokenizer\n",
    "        sents = sent_tokenize(text)\n",
    "        # the sentences provided by NLTK still have newline characters in them, inside the lines (as they come from a play, \n",
    "        # not a book) which need to be removed\n",
    "        # we also only need the sentences with \"you\" pronouns, and an option to only pick out sentences with one such pronoun\n",
    "        # present.\n",
    "    double_sents = []  # for more than one occurrence of \"you\"\n",
    "    single_sents = []  # for exactly one occurrence of \"you\"\n",
    "    for sent in sents:\n",
    "        tracker = 0  # to track how many \"you\" forms there are in the sentence\n",
    "        for element in word_tokenize(sent):\n",
    "            if '_SG' in element or '_PL' in element or '_UNK' in element:\n",
    "                tracker += 1\n",
    "        if tracker > 1:\n",
    "            double_sents.append(sent.replace('\\n', ' ').replace('\\t', '').replace('\\\\', ''))\n",
    "        elif tracker == 1:\n",
    "            single_sents.append(sent.replace('\\n', ' ').replace('\\t', '').replace('\\\\', ''))\n",
    "        else:  # if there are no \"you\" forms\n",
    "            continue\n",
    "    \n",
    "    # deciding which sentences will be returned by the function, the ones with only one \"you\" or also the ones with\n",
    "    # multiple ones\n",
    "    if double == False:\n",
    "        you_sents = single_sents\n",
    "    else:\n",
    "        you_sents = single_sents + double_sents\n",
    "\n",
    "    return you_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4cba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_files(file_list, double=False):\n",
    "# this function allows for obtaining you-sentences from many files simultaneously\n",
    "    all_sents = []\n",
    "    for filename in file_list:\n",
    "        file_sents = extract_you_sents(filename, double=double)\n",
    "        all_sents += file_sents\n",
    "    \n",
    "    return all_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284f8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(sentence_list, tokenizer):\n",
    "    # this function takes in a list of sentences with \"you\" pronoun(s) in them and creates samples of the shape (tokenized_sent,\n",
    "    # class, pronoun_index, sentence_length)\n",
    "    # the \"you\" pronouns are defined as the following variants: you -> [ye] [your] [yours] [yourself] [yourselves], as used\n",
    "    # in the original study in the corpus analysis software AntConc\n",
    "    # maximum_length is set to 200 as this is a bit above what the longest sentence is in this dataset; however, since we are\n",
    "    # not feeding this to the tokenizer in batches, we cannot just pad \n",
    "    prons = ['you', 'ye', 'your', 'yours', 'yourself', 'yourselves']  # all the \"you\" forms\n",
    "    converted_prons = tokenizer.convert_tokens_to_ids(prons)\n",
    "    conv_underscore = tokenizer.convert_tokens_to_ids('_')\n",
    "    \n",
    "    all_samples = []\n",
    "    for sent in sentence_list:\n",
    "        sent_cls = []\n",
    "        tokenized = tokenizer(sent)  # tokenizing the sentence using BERT tokenizer\n",
    "        for i in range(0, len(tokenized['input_ids'])):\n",
    "            # iterating through the tokenized sentence to find all the classes\n",
    "            if tokenized['input_ids'][i] == conv_underscore:\n",
    "                cls = tokenizer.convert_ids_to_tokens(tokenized['input_ids'][i+1])\n",
    "                sent_cls.append(cls)\n",
    "\n",
    "        # removing the annotation (as now we have that information ordered in sent_clss)\n",
    "        new_sent = sent.replace('_SG', '').replace('_PL', '').replace('_UNK', '')\n",
    "        \n",
    "        # creating and appending a sample for each \"you\" pronoun in the sentence; it is necessary to use the tokenizer on\n",
    "        # it to retrieve the appropriate index (and this is important as we have samples where there may be more than one\n",
    "        # \"you\" token); we do not save the tokenized sentence as we actually want those to be padded to the length of the\n",
    "        # longest sentence in the batch, which is also why we are saving the length here\n",
    "        full_sent = tokenizer(new_sent)\n",
    "        for i in range(0, len(full_sent['input_ids'])):\n",
    "            if full_sent['input_ids'][i] in converted_prons:\n",
    "                cls = sent_cls.pop(0)\n",
    "                idx = i  \n",
    "                all_samples.append([new_sent, cls, idx])\n",
    "    \n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b99d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_splits(samples, train_split=0.8, test_split=0.2, equalize=True):\n",
    "    # creating a function to mix and split the data stored in a list according to parameters introduced by the user\n",
    "    # avoiding potential errors\n",
    "    if (train_split + test_split) != 1:\n",
    "        print('Invalid data split proportions!')\n",
    "        return\n",
    "    \n",
    "    if equalize == False:\n",
    "        random.shuffle(samples)  # shuffling the data \n",
    "        test_size = math.ceil(len(samples) * test_split)  # deciding the point at which to split the samples\n",
    "        test_samples = samples[:test_size]\n",
    "        train_samples = samples[test_size:]\n",
    "    \n",
    "    # implementing \"equalizing\" so that all classes are equally represented, removing UNK as that one is significantly smaller\n",
    "    # than the other classes, effectively turning this into a binary classification problem\n",
    "    else:\n",
    "        sg_samples = []\n",
    "        pl_samples = []\n",
    "        for sample in samples:\n",
    "            if sample[1] == 'sg':\n",
    "                sg_samples.append(sample)\n",
    "            elif sample[1] == 'pl':\n",
    "                pl_samples.append(sample)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        if len(sg_samples) > len(pl_samples):\n",
    "            max_len = len(pl_samples)\n",
    "        else:\n",
    "            max_len = len(sg_samples)\n",
    "        \n",
    "        test_size = math.ceil(max_len * test_split)\n",
    "            \n",
    "        random.shuffle(sg_samples)\n",
    "        random.shuffle(pl_samples)\n",
    "        \n",
    "        selected_sg = sg_samples[:max_len]\n",
    "        selected_pl = pl_samples[:max_len]\n",
    "        \n",
    "        test_sg = selected_sg[:test_size]\n",
    "        train_sg = selected_sg[test_size:]\n",
    "        \n",
    "        test_pl = selected_pl[:test_size]\n",
    "        train_pl = selected_pl[test_size:]\n",
    "        \n",
    "        test_samples = test_sg + test_pl\n",
    "        train_samples = train_sg + train_pl\n",
    "        \n",
    "        random.shuffle(test_samples)\n",
    "        random.shuffle(train_samples)\n",
    "    \n",
    "    return train_samples, test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d5840",
   "metadata": {},
   "source": [
    "### DATA-ENCODING AND BATCHING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37fb3b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT is imported and set in eval mode so that we can retrieve embeddings from it\n",
    "bert_model = BertModel.from_pretrained(model_name, return_dict=True, output_hidden_states=True)\n",
    "bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "339a6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(input_ids, attention_mask, bert_device):\n",
    "    # a function to retrieve the word embeddings from BERT, required BERT to be initialized as bert_model beforehand and put\n",
    "    # in eval mode (see above), all of that with return_hidden_states=True\n",
    "    # inspired by https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#3-extracting-embeddings\n",
    "    # the same function was used in my Assignment 1 for this course\n",
    "    with torch.no_grad():\n",
    "        # getting the parts of the batch that are relevant\n",
    "        bert_model.to(bert_device)\n",
    "        output = bert_model(input_ids, attention_mask)\n",
    "        # hidden states for every layer are stored here\n",
    "        hidden_states = output[2]\n",
    "        # there are 13 elements in the hidden states, meaning the initial embeddings and hidden states from 12 layers;\n",
    "        # according to the link I provided above, there are mant approaches for what elements of these to use as word\n",
    "        # embeddings; I will use the second-to-last hidden layer\n",
    "        penultimate_layer = hidden_states[11]\n",
    "        # the penultimate layer now has the shape of batch * max_len of the sentence * 768 (BERT embedding size)\n",
    "    return penultimate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23e83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareCollate():\n",
    "    # custom collate class that processes the data from the batched list of samples as they are accessed \n",
    "    def __init__(self, tokenizer, device, bert_device):\n",
    "        # defining the tokenizer and the devices on which BERT and the actual model will run\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.bert_device = bert_device\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        # performing the necessary operations on every batch\n",
    "        sentences = []\n",
    "        classes = []\n",
    "        indices = []\n",
    "        \n",
    "        for element in batch:\n",
    "            sentences.append(element[0]) \n",
    "            classes.append(element[1])\n",
    "            indices.append(torch.tensor([element[2]]))\n",
    "        \n",
    "        # one-hot encoding classes    \n",
    "        for i in range(0, len(classes)):\n",
    "            if classes[i] == 'sg':\n",
    "                classes[i] = torch.FloatTensor([1])\n",
    "            elif classes[i] == 'pl':\n",
    "                classes[i] = torch.FloatTensor([0])\n",
    "\n",
    "        # calling the BERT tokenizer on the sentences\n",
    "        tokens = self.tokenizer(sentences, \n",
    "                                            add_special_tokens=True, \n",
    "                                            return_tensors='pt',\n",
    "                                            padding=True, \n",
    "                                            return_attention_mask=True,\n",
    "                                            is_split_into_words=False)\n",
    "         \n",
    "        input_ids=tokens['input_ids'].to(self.bert_device)\n",
    "        attention_masks=tokens['attention_mask'].to(self.bert_device)\n",
    "        # calling the embeddings function since we want to feed the network the BERT embeddings; make sure that BERT is\n",
    "        # on the same device as the rest before that\n",
    "        # all of the output is moved to the model device, classes and indices are stacked since it has to be a tensor, \n",
    "        # not a list\n",
    "        bert_embeddings = get_embeddings(input_ids, attention_masks, self.bert_device).to(self.device)  \n",
    "        classes = torch.stack(classes).to(self.device)\n",
    "        indices = torch.stack(indices).to(self.device)\n",
    "        \n",
    "        return bert_embeddings, classes, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebccc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shakespeare_dataloader(data, tokenizer, device, bert_device, batch_size=32, shuffle=True): \n",
    "    # little function to easily obtain dataloaders using our dataset and custom ShakespeareCollate class which does all the\n",
    "    # hard work of transforming sentences into BERT embedding representations, one-hot-encoding the classes and turning what\n",
    "    # is needed to be turned into tensors.\n",
    "    loader = DataLoader(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=True,\n",
    "        collate_fn=ShakespeareCollate(tokenizer, device, bert_device) )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe48fc5",
   "metadata": {},
   "source": [
    "### TRAINING LOOP AND MODEL SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1efdc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareanClassifier(nn.Module):\n",
    "    # class of the model itself; \n",
    "    def __init__(self, hidden_size):\n",
    "        super(ShakespeareanClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = 1  # for the binary classification 0/1\n",
    "        self.embedding_dim = 768  # BERT embedding size\n",
    "\n",
    "\n",
    "        # the text processing layer is a bidirectional LSTM; the input size here is the size of BERT embeddings, the hidden\n",
    "        # size is set by the user; it is a bidirectional LSTM \n",
    "        self.LSTM = nn.LSTM(\n",
    "                            input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_size, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True, \n",
    "                            bidirectional=True\n",
    "                            )\n",
    "        \n",
    "        self.classification = nn.Sequential( \n",
    "                            nn.Dropout(0.05),\n",
    "                            nn.Linear(self.hidden_size*2, self.hidden_size),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Linear(self.hidden_size, self.output_dim),\n",
    "                            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, bert_embeddings, indices, device):\n",
    "        # for calling the model we need to input the BERT embeddings from the batch \n",
    "        converted_embeddings = bert_embeddings.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        # the captions are fed through the LSTM, and the hidden state at the index of the pronoun is saved, as per the \n",
    "        # documentation \"When bidirectional=True, output will contain a concatenation of the forward and reverse hidden \n",
    "        # states at each time step in the sequence.\" (https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html), so\n",
    "        # I do not need to concatenate anything myself and selecting an indexed timestep representation already gives\n",
    "        # me something that a) is double the size of the hidden layer b) contains information from both directions\n",
    "        timestep_representation, (final_hidden, final_cell) = self.LSTM(converted_embeddings)\n",
    "        processed_embeddings = torch.stack([tp[i] for i, tp in zip(indices, timestep_representation)])\n",
    "        # the data is fed to the classification layer\n",
    "        output = self.classification(processed_embeddings)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "962e53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params, train_samples):\n",
    "    # this function is intended for training an instance of the ShakespeareanClassifier\n",
    "    model.to(params['device'])\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "    for epoch in range(1,params['epochs']+1):  # so that it prints out nicely\n",
    "    \n",
    "        train_iter = shakespeare_dataloader(\n",
    "            train_samples, tokenizer, params['device'], params['bert_device'], batch_size=params['batch_size'], shuffle=True\n",
    "        )\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_iter):\n",
    "\n",
    "            if True:  # i < 20: For testing\n",
    "                sentences = batch[0]\n",
    "                classes = batch[1]\n",
    "                indices = batch[2]\n",
    "\n",
    "                # send your batch of sentences to the model\n",
    "                output = model(sentences, indices, params['device'])\n",
    "                \n",
    "                loss = loss_function(torch.squeeze(output, dim=1), classes)  # output is squeezed to fit the original classes\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                if i%5==0:\n",
    "                    print(f' Batch {i} : Average Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "\n",
    "                # calculate gradients\n",
    "                loss.backward()\n",
    "                # update model weights\n",
    "                optimizer.step()\n",
    "                # reset gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        print(f'Epoch {epoch} : Average Training Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "775e02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(item, file_name):\n",
    "    # a small function intended to be used to save a trained model\n",
    "    pickle.dump(item, open(file_name, 'wb'))\n",
    "\n",
    "def load(file_name):\n",
    "    # a small function intended to be used to load a trained model\n",
    "    item = pickle.load(open(file_name, 'rb'))\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcaacc3",
   "metadata": {},
   "source": [
    "### TESTING AND EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb74dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, params, test_samples):\n",
    "    model.to(params['device'])\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_classes = []\n",
    "    with torch.no_grad():\n",
    "        test_iter = shakespeare_dataloader(\n",
    "            test_samples, tokenizer, params['device'], params['bert_device'], batch_size=params['batch_size'], shuffle=False\n",
    "        )    \n",
    "        for j, batch in enumerate(test_iter):\n",
    "            sentences = batch[0]\n",
    "            indices = batch[2]\n",
    "\n",
    "            o = model(sentences, indices, params['device'])\n",
    "            predictions = torch.squeeze(o).tolist()  # making sure that we get predictions in the correct format\n",
    "            # encoding the predictions to reflect not probabilities, but classes; \n",
    "            for i in range(0, len(predictions)):\n",
    "                if predictions[i] > 0.5:\n",
    "                    predictions[i] = 1.0\n",
    "                else:\n",
    "                    predictions[i] = 0.0\n",
    "            all_predictions += predictions\n",
    "            all_classes += torch.squeeze(batch[1]).tolist()\n",
    "\n",
    "    print('Testing complete!')\n",
    "\n",
    "    return all_predictions, all_classes              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db9b60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(predicted_classes, true_classes):\n",
    "    # this function goes over the output of the testing function and provides some basic evaluation measures, such as\n",
    "    # accuracy, recall, precision, and f1, using sklearn's functions (although I did manually implement it in assignment 1)\n",
    "    print('The following measures have been recorded for this model:')\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(true_classes, predicted_classes)\n",
    "    recall = sklearn.metrics.recall_score(true_classes, predicted_classes)\n",
    "    precision = sklearn.metrics.precision_score(true_classes, predicted_classes)\n",
    "    f1 = sklearn.metrics.f1_score(true_classes, predicted_classes)\n",
    "    \n",
    "    print(f'\\tAccuracy = {accuracy}')\n",
    "    print(f'\\tRecall = {recall}')\n",
    "    print(f'\\tPrecision = {precision}')\n",
    "    print(f'\\tF1 = {f1}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "760c5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(predicted_classes, test_samples):\n",
    "    # a function for easy making of a dataframe to display the results together with the sentences\n",
    "    rows = []\n",
    "    for i in range(0, len(predicted_classes)):\n",
    "        prediction = predicted_classes[i]\n",
    "        if prediction == 1.0:\n",
    "            prediction = 'sg'\n",
    "        else:\n",
    "            prediction = 'pl'\n",
    "        truth = test_samples[i][1]\n",
    "        sentence = test_samples[i][0]\n",
    "        rows.append([sentence, prediction, truth])\n",
    "\n",
    "    model_df = pd.DataFrame(rows)\n",
    "    model_df.columns = [\"sentence\", \"predicted class\", \"true class\"]\n",
    "\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bccabd",
   "metadata": {},
   "source": [
    "### RUNNING THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "689c9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "you_sents = extract_from_files(shakespeare_plays, double=True)\n",
    "samples = create_samples(you_sents, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d018b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, test_samples = samples_splits(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47761926",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(train_samples, 'train_samples_full.pickle')\n",
    "save(test_samples, 'test_samples_full.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0a9a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 0 : Average Loss = 0.69039\n",
      " Batch 5 : Average Loss = 0.69695\n",
      " Batch 10 : Average Loss = 0.68914\n",
      " Batch 15 : Average Loss = 0.6905\n",
      " Batch 20 : Average Loss = 0.68573\n",
      " Batch 25 : Average Loss = 0.68191\n",
      " Batch 30 : Average Loss = 0.67996\n",
      " Batch 35 : Average Loss = 0.67833\n",
      " Batch 40 : Average Loss = 0.67587\n",
      "Epoch 1 : Average Training Loss = 0.67619\n",
      " Batch 0 : Average Loss = 0.61459\n",
      " Batch 5 : Average Loss = 0.59897\n",
      " Batch 10 : Average Loss = 0.61753\n",
      " Batch 15 : Average Loss = 0.62454\n",
      " Batch 20 : Average Loss = 0.60617\n",
      " Batch 25 : Average Loss = 0.60339\n",
      " Batch 30 : Average Loss = 0.59976\n",
      " Batch 35 : Average Loss = 0.59833\n",
      " Batch 40 : Average Loss = 0.59476\n",
      "Epoch 2 : Average Training Loss = 0.59147\n",
      " Batch 0 : Average Loss = 0.45151\n",
      " Batch 5 : Average Loss = 0.49626\n",
      " Batch 10 : Average Loss = 0.45687\n",
      " Batch 15 : Average Loss = 0.486\n",
      " Batch 20 : Average Loss = 0.48431\n",
      " Batch 25 : Average Loss = 0.48427\n",
      " Batch 30 : Average Loss = 0.45084\n",
      " Batch 35 : Average Loss = 0.45861\n",
      " Batch 40 : Average Loss = 0.45152\n",
      "Epoch 3 : Average Training Loss = 0.45577\n",
      " Batch 0 : Average Loss = 0.18802\n",
      " Batch 5 : Average Loss = 0.37714\n",
      " Batch 10 : Average Loss = 0.32363\n",
      " Batch 15 : Average Loss = 0.33666\n",
      " Batch 20 : Average Loss = 0.32775\n",
      " Batch 25 : Average Loss = 0.31471\n",
      " Batch 30 : Average Loss = 0.29433\n",
      " Batch 35 : Average Loss = 0.29105\n",
      " Batch 40 : Average Loss = 0.28404\n",
      "Epoch 4 : Average Training Loss = 0.29006\n",
      " Batch 0 : Average Loss = 0.39935\n",
      " Batch 5 : Average Loss = 0.15868\n",
      " Batch 10 : Average Loss = 0.17449\n",
      " Batch 15 : Average Loss = 0.17459\n",
      " Batch 20 : Average Loss = 0.1638\n",
      " Batch 25 : Average Loss = 0.14887\n",
      " Batch 30 : Average Loss = 0.143\n",
      " Batch 35 : Average Loss = 0.14028\n",
      " Batch 40 : Average Loss = 0.13776\n",
      "Epoch 5 : Average Training Loss = 0.13823\n",
      " Batch 0 : Average Loss = 0.08779\n",
      " Batch 5 : Average Loss = 0.09081\n",
      " Batch 10 : Average Loss = 0.09308\n",
      " Batch 15 : Average Loss = 0.0819\n",
      " Batch 20 : Average Loss = 0.07776\n",
      " Batch 25 : Average Loss = 0.07391\n",
      " Batch 30 : Average Loss = 0.06618\n",
      " Batch 35 : Average Loss = 0.06525\n",
      " Batch 40 : Average Loss = 0.06042\n",
      "Epoch 6 : Average Training Loss = 0.05943\n",
      " Batch 0 : Average Loss = 0.0079\n",
      " Batch 5 : Average Loss = 0.01094\n",
      " Batch 10 : Average Loss = 0.01018\n",
      " Batch 15 : Average Loss = 0.01151\n",
      " Batch 20 : Average Loss = 0.01016\n",
      " Batch 25 : Average Loss = 0.00929\n",
      " Batch 30 : Average Loss = 0.01109\n",
      " Batch 35 : Average Loss = 0.01243\n",
      " Batch 40 : Average Loss = 0.01203\n",
      "Epoch 7 : Average Training Loss = 0.01213\n",
      " Batch 0 : Average Loss = 0.00731\n",
      " Batch 5 : Average Loss = 0.00657\n",
      " Batch 10 : Average Loss = 0.00619\n",
      " Batch 15 : Average Loss = 0.00632\n",
      " Batch 20 : Average Loss = 0.00663\n",
      " Batch 25 : Average Loss = 0.00585\n",
      " Batch 30 : Average Loss = 0.00569\n",
      " Batch 35 : Average Loss = 0.006\n",
      " Batch 40 : Average Loss = 0.006\n",
      "Epoch 8 : Average Training Loss = 0.00593\n",
      " Batch 0 : Average Loss = 0.00747\n",
      " Batch 5 : Average Loss = 0.00368\n",
      " Batch 10 : Average Loss = 0.00267\n",
      " Batch 15 : Average Loss = 0.00245\n",
      " Batch 20 : Average Loss = 0.00252\n",
      " Batch 25 : Average Loss = 0.00235\n",
      " Batch 30 : Average Loss = 0.00248\n",
      " Batch 35 : Average Loss = 0.00253\n",
      " Batch 40 : Average Loss = 0.00262\n",
      "Epoch 9 : Average Training Loss = 0.00258\n",
      " Batch 0 : Average Loss = 0.00613\n",
      " Batch 5 : Average Loss = 0.00227\n",
      " Batch 10 : Average Loss = 0.00196\n",
      " Batch 15 : Average Loss = 0.00163\n",
      " Batch 20 : Average Loss = 0.0018\n",
      " Batch 25 : Average Loss = 0.0016\n",
      " Batch 30 : Average Loss = 0.00157\n",
      " Batch 35 : Average Loss = 0.00151\n",
      " Batch 40 : Average Loss = 0.00148\n",
      "Epoch 10 : Average Training Loss = 0.00146\n"
     ]
    }
   ],
   "source": [
    "params = {'lr':0.00005, 'batch_size':8, 'hidden_size':1024, 'epochs':10, 'device':'cuda:2', 'bert_device':'cuda:3'} \n",
    "model = ShakespeareanClassifier(params['hidden_size'])\n",
    "trained_model = train(model, params, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "056abb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(trained_model, 'trained_model_acc80.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c476f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "predicted_classes, true_classes = test(trained_model, params, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6c2dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following measures have been recorded for this model:\n",
      "\tAccuracy = 0.8\n",
      "\tRecall = 0.7692307692307693\n",
      "\tPrecision = 0.8108108108108109\n",
      "\tF1 = 0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "measures(predicted_classes, true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d8d8a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicted class</th>\n",
       "      <th>true class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Call you this railing?</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My good friends, I'll leave you till night.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ay.--Fare you well, fair gentleman.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Orlando doth commend him to you both, And to that youth he calls his Rosalind He sends this bloody napkin.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beggar that I am, I am even poor in thanks; but I thank you, and sure, dear friends, my thanks are too dear a halfpenny.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Therefore put you in your best array, bid your friends; for if you will be married tomorrow, you shall, and to Rosalind, if you will.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>So please you, he is here at the door and importunes access to you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not out of your apparel, and yet out of your suit.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Moreover that we much did long to see you, The need we have to use you did provoke Our hasty sending.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>And I charge you, O men, for the love you bear to women--as I perceive by your simpering, none of you hates them--that between you and the women the play may please.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Look you lisp and wear strange suits, disable all the benefits of your own country, be out of love with your nativity, and almost chide God for making you that countenance you are, or I will scarce think you have swam in a gondola.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Both your Majesties Might, by the sovereign power you have of us, Put your dread pleasures more into command Than to entreaty.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>To you I give myself, for I am yours.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>If this be so, why blame you me to love you?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>By my troth, and in good earnest, and so God mend me, and by all pretty oaths that are not dangerous, if you break one jot of your promise or come one minute behind your hour, I will think you the most pathetical break-promise, and the most hollow lover, and the most unworthy of her you call Rosalind that may be chosen out of the gross band of the unfaithful.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Let me comply with you in this garb, lest my extent to the players, which, I tell you, must show fairly outwards, should more appear like entertainment than yourselves.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>And a chain, that you once wore, about his neck.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Where is this king?--Sirs, stand you all without.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>So by my former lecture and advice Shall you my son.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Then one of you will prove a shrunk panel and, like green timber, warp, warp.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>We must have your doublet and hose plucked over your head and show the world what the bird hath done to her own nest.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I will tell you the beginning, and if it please your Ladyships, you may see the end, for the best is yet to do, and here, where you are, they are coming to perform it.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Why do people love you?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Speak to him, ladies; see if you can move him.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>These blazes, daughter, Giving more light than heat, extinct in both Even in their promise as it is a-making, You must not take for fire.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I will not sort you with the rest of my servants, for, to speak to you like an honest man, I am most dreadfully attended.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How say you, then?</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Call me what instrument you will, though you can fret me, you cannot play upon me.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I thank you, sir, and pray you tell me this: Which of the two was daughter of the duke That here was at the wrestling?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I will tell you why; so shall my anticipation prevent your discovery, and your secrecy to the King and Queen molt no feather.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>So shall I hope your virtues Will bring him to his wonted way again, To both your honors.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>But you 'll be secret?</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>But you must know your father lost a father, That father lost, lost his, and the survivor bound In filial obligation for some term To do obsequious sorrow.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Nor have we herein barred Your better wisdoms, which have freely gone With this affair along.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Hold you the watch tonight?</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>You have too courtly a wit for me.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Read on this book, That show of such an exercise may color Your loneliness.--We are oft to blame in this ('Tis too much proved), that with devotion's visage And pious action we do sugar o'er The devil himself.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>And I am your Rosalind.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>You were sent for, and there is a kind of confession in your looks which your modesties have not craft enough to color.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Come, give us a taste of your quality.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\"And, in part, him, but,\" you may say, \"not well.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>No, you will reveal it.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>And I charge you, O men, for the love you bear to women--as I perceive by your simpering, none of you hates them--that between you and the women the play may please.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>I beseech you, punish me not with your hard thoughts, wherein I confess me much guilty to deny so fair and excellent ladies anything.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Arm you, I pray you, to this speedy voyage, For we will fetters put about this fear, Which now goes too free-footed.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>But let me conjure you by the rights of our fellowship, by the consonancy of our youth, by the obligation of our ever-preserved love, and by what more dear a better proposer can charge you withal: be even and direct with me whether you were sent for or no.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Fear it, Ophelia; fear it, my dear sister, And keep you in the rear of your affection, Out of the shot and danger of desire.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>I charge you, O women, for the love you bear to men, to like as much of this play as please you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I will not trouble you As yet to question you about your fortunes.-- Give us some music, and, good cousin, sing.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Farewell, and let your haste commend your duty.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>But you are no such man.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>You were sent for, and there is a kind of confession in your looks which your modesties have not craft enough to color.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>You do love this maid?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>You, laying these slight sullies on my son, As 'twere a thing a little soiled i' th' working, Mark you, your party in converse, him you would sound, Having ever seen in the prenominate crimes The youth you breathe of guilty, be assured He closes with you in this consequence: \"Good sir,\" or so, or \"friend,\" or \"gentleman,\" According to the phrase or the addition Of man and country--  Very good, my lord.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>I know you are my eldest brother, and in the gentle condition of blood you should so know me.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>I your commission will forthwith dispatch, And he to England shall along with you.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>But let me conjure you by the rights of our fellowship, by the consonancy of our youth, by the obligation of our ever-preserved love, and by what more dear a better proposer can charge you withal: be even and direct with me whether you were sent for or no.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>But let your fair eyes and gentle wishes go with me to my trial, wherein, if I be foiled, there is but one shamed that was never gracious; if killed, but one dead that is willing to be so.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>I will not sort you with the rest of my servants, for, to speak to you like an honest man, I am most dreadfully attended.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>I do not desire you to please me.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>'Twas I, but 'tis not I. I do not shame To tell you what I was, since my conversion So sweetly tastes, being the thing I am.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Whiles you chid me, I did love.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>I would have told you of good wrestling, which you have lost the sight of.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Good sir, I do in friendship counsel you To leave this place.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>So shall you hear Of carnal, bloody, and unnatural acts, Of accidental judgments, casual slaughters, Of deaths put on by cunning and forced cause, And, in this upshot, purposes mistook Fall'n on th' inventors' heads.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Your loves, as mine to you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>But your news is not true.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>What you will, Monsieur Jaques.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Touching this vision here, It is an honest ghost--that let me tell you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>And I beseech you instantly to visit My too much changed son.--Go, some of you, And bring these gentlemen where Hamlet is.</td>\n",
       "      <td>pl</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Keep you your word, O duke, to give your daughter,-- You yours, Orlando, to receive his daughter.-- Keep you your word, Phoebe, that you 'll marry me, Or else, refusing me, to wed this shepherd.-- Keep your word, Silvius, that you 'll marry her If she refuse me.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>But, in the beaten way of friendship, what make you at Elsinore?</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>I shall obey you.</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Will you sterner be Than he that dies and lives by bloody drops?</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>I would not hear your enemy say so, Nor shall you do my ear that violence To make it truster of your own report Against yourself.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Yet, though I distrust, Discomfort you, my lord, it nothing must.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>For your father's remembrance, be at accord.</td>\n",
       "      <td>sg</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Keep you your word, O duke, to give your daughter,-- You yours, Orlando, to receive his daughter.-- Keep you your word, Phoebe, that you 'll marry me, Or else, refusing me, to wed this shepherd.-- Keep your word, Silvius, that you 'll marry her If she refuse me.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>But I answer you right painted cloth, from whence you have studied your questions.</td>\n",
       "      <td>sg</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Will you go?</td>\n",
       "      <td>pl</td>\n",
       "      <td>sg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                 sentence  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                  Call you this railing?   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                             My good friends, I'll leave you till night.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                     Ay.--Fare you well, fair gentleman.   \n",
       "3                                                                                                                                                                                                                                                                                                              Orlando doth commend him to you both, And to that youth he calls his Rosalind He sends this bloody napkin.   \n",
       "4                                                                                                                                                                                                                                                                                                Beggar that I am, I am even poor in thanks; but I thank you, and sure, dear friends, my thanks are too dear a halfpenny.   \n",
       "5                                                                                                                                                                                                                                                                                   Therefore put you in your best array, bid your friends; for if you will be married tomorrow, you shall, and to Rosalind, if you will.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                     So please you, he is here at the door and importunes access to you.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                      Not out of your apparel, and yet out of your suit.   \n",
       "8                                                                                                                                                                                                                                                                                                                   Moreover that we much did long to see you, The need we have to use you did provoke Our hasty sending.   \n",
       "9                                                                                                                                                                                                                                                   And I charge you, O men, for the love you bear to women--as I perceive by your simpering, none of you hates them--that between you and the women the play may please.   \n",
       "10                                                                                                                                                                                Look you lisp and wear strange suits, disable all the benefits of your own country, be out of love with your nativity, and almost chide God for making you that countenance you are, or I will scarce think you have swam in a gondola.   \n",
       "11                                                                                                                                                                                                                                                                                         Both your Majesties Might, by the sovereign power you have of us, Put your dread pleasures more into command Than to entreaty.   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                  To you I give myself, for I am yours.   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                           If this be so, why blame you me to love you?   \n",
       "14                                              By my troth, and in good earnest, and so God mend me, and by all pretty oaths that are not dangerous, if you break one jot of your promise or come one minute behind your hour, I will think you the most pathetical break-promise, and the most hollow lover, and the most unworthy of her you call Rosalind that may be chosen out of the gross band of the unfaithful.   \n",
       "15                                                                                                                                                                                                                                               Let me comply with you in this garb, lest my extent to the players, which, I tell you, must show fairly outwards, should more appear like entertainment than yourselves.   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                       And a chain, that you once wore, about his neck.   \n",
       "17                                                                                                                                                                                                                                                                                                                                                                      Where is this king?--Sirs, stand you all without.   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                   So by my former lecture and advice Shall you my son.   \n",
       "19                                                                                                                                                                                                                                                                                                                                          Then one of you will prove a shrunk panel and, like green timber, warp, warp.   \n",
       "20                                                                                                                                                                                                                                                                                                  We must have your doublet and hose plucked over your head and show the world what the bird hath done to her own nest.   \n",
       "21                                                                                                                                                                                                                                                I will tell you the beginning, and if it please your Ladyships, you may see the end, for the best is yet to do, and here, where you are, they are coming to perform it.   \n",
       "22                                                                                                                                                                                                                                                                                                                                                                                                Why do people love you?   \n",
       "23                                                                                                                                                                                                                                                                                                                                                                         Speak to him, ladies; see if you can move him.   \n",
       "24                                                                                                                                                                                                                                                                              These blazes, daughter, Giving more light than heat, extinct in both Even in their promise as it is a-making, You must not take for fire.   \n",
       "25                                                                                                                                                                                                                                                                                              I will not sort you with the rest of my servants, for, to speak to you like an honest man, I am most dreadfully attended.   \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                     How say you, then?   \n",
       "27                                                                                                                                                                                                                                                                                                                                     Call me what instrument you will, though you can fret me, you cannot play upon me.   \n",
       "28                                                                                                                                                                                                                                                                                                 I thank you, sir, and pray you tell me this: Which of the two was daughter of the duke That here was at the wrestling?   \n",
       "29                                                                                                                                                                                                                                                                                          I will tell you why; so shall my anticipation prevent your discovery, and your secrecy to the King and Queen molt no feather.   \n",
       "30                                                                                                                                                                                                                                                                                                                              So shall I hope your virtues Will bring him to his wonted way again, To both your honors.   \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                                 But you 'll be secret?   \n",
       "32                                                                                                                                                                                                                                                            But you must know your father lost a father, That father lost, lost his, and the survivor bound In filial obligation for some term To do obsequious sorrow.   \n",
       "33                                                                                                                                                                                                                                                                                                                          Nor have we herein barred Your better wisdoms, which have freely gone With this affair along.   \n",
       "34                                                                                                                                                                                                                                                                                                                                                                                            Hold you the watch tonight?   \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                     You have too courtly a wit for me.   \n",
       "36                                                                                                                                                                                                      Read on this book, That show of such an exercise may color Your loneliness.--We are oft to blame in this ('Tis too much proved), that with devotion's visage And pious action we do sugar o'er The devil himself.   \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                And I am your Rosalind.   \n",
       "38                                                                                                                                                                                                                                                                                                You were sent for, and there is a kind of confession in your looks which your modesties have not craft enough to color.   \n",
       "39                                                                                                                                                                                                                                                                                                                                                                                 Come, give us a taste of your quality.   \n",
       "40                                                                                                                                                                                                                                                                                                                                                                      \"And, in part, him, but,\" you may say, \"not well.   \n",
       "41                                                                                                                                                                                                                                                                                                                                                                                                No, you will reveal it.   \n",
       "42                                                                                                                                                                                                                                                  And I charge you, O men, for the love you bear to women--as I perceive by your simpering, none of you hates them--that between you and the women the play may please.   \n",
       "43                                                                                                                                                                                                                                                                                  I beseech you, punish me not with your hard thoughts, wherein I confess me much guilty to deny so fair and excellent ladies anything.   \n",
       "44                                                                                                                                                                                                                                                                                                   Arm you, I pray you, to this speedy voyage, For we will fetters put about this fear, Which now goes too free-footed.   \n",
       "45                                                                                                                                                       But let me conjure you by the rights of our fellowship, by the consonancy of our youth, by the obligation of our ever-preserved love, and by what more dear a better proposer can charge you withal: be even and direct with me whether you were sent for or no.   \n",
       "46                                                                                                                                                                                                                                                                                           Fear it, Ophelia; fear it, my dear sister, And keep you in the rear of your affection, Out of the shot and danger of desire.   \n",
       "47                                                                                                                                                                                                                                                                                                                       I charge you, O women, for the love you bear to men, to like as much of this play as please you.   \n",
       "48                                                                                                                                                                                                                                                                                                       I will not trouble you As yet to question you about your fortunes.-- Give us some music, and, good cousin, sing.   \n",
       "49                                                                                                                                                                                                                                                                                                                                                                        Farewell, and let your haste commend your duty.   \n",
       "50                                                                                                                                                                                                                                                                                                                                                                                               But you are no such man.   \n",
       "51                                                                                                                                                                                                                                                                                                You were sent for, and there is a kind of confession in your looks which your modesties have not craft enough to color.   \n",
       "52                                                                                                                                                                                                                                                                                                                                                                                                 You do love this maid?   \n",
       "53  You, laying these slight sullies on my son, As 'twere a thing a little soiled i' th' working, Mark you, your party in converse, him you would sound, Having ever seen in the prenominate crimes The youth you breathe of guilty, be assured He closes with you in this consequence: \"Good sir,\" or so, or \"friend,\" or \"gentleman,\" According to the phrase or the addition Of man and country--  Very good, my lord.   \n",
       "54                                                                                                                                                                                                                                                                                                                          I know you are my eldest brother, and in the gentle condition of blood you should so know me.   \n",
       "55                                                                                                                                                                                                                                                                                                                                     I your commission will forthwith dispatch, And he to England shall along with you.   \n",
       "56                                                                                                                                                       But let me conjure you by the rights of our fellowship, by the consonancy of our youth, by the obligation of our ever-preserved love, and by what more dear a better proposer can charge you withal: be even and direct with me whether you were sent for or no.   \n",
       "57                                                                                                                                                                                                                           But let your fair eyes and gentle wishes go with me to my trial, wherein, if I be foiled, there is but one shamed that was never gracious; if killed, but one dead that is willing to be so.   \n",
       "58                                                                                                                                                                                                                                                                                              I will not sort you with the rest of my servants, for, to speak to you like an honest man, I am most dreadfully attended.   \n",
       "59                                                                                                                                                                                                                                                                                                                                                                                      I do not desire you to please me.   \n",
       "60                                                                                                                                                                                                                                                                                           'Twas I, but 'tis not I. I do not shame To tell you what I was, since my conversion So sweetly tastes, being the thing I am.   \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                        Whiles you chid me, I did love.   \n",
       "62                                                                                                                                                                                                                                                                                                                                             I would have told you of good wrestling, which you have lost the sight of.   \n",
       "63                                                                                                                                                                                                                                                                                                                                                          Good sir, I do in friendship counsel you To leave this place.   \n",
       "64                                                                                                                                                                                               So shall you hear Of carnal, bloody, and unnatural acts, Of accidental judgments, casual slaughters, Of deaths put on by cunning and forced cause, And, in this upshot, purposes mistook Fall'n on th' inventors' heads.   \n",
       "65                                                                                                                                                                                                                                                                                                                                                                                            Your loves, as mine to you.   \n",
       "66                                                                                                                                                                                                                                                                                                                                                                                             But your news is not true.   \n",
       "67                                                                                                                                                                                                                                                                                                                                                                                        What you will, Monsieur Jaques.   \n",
       "68                                                                                                                                                                                                                                                                                                                                                Touching this vision here, It is an honest ghost--that let me tell you.   \n",
       "69                                                                                                                                                                                                                                                                                             And I beseech you instantly to visit My too much changed son.--Go, some of you, And bring these gentlemen where Hamlet is.   \n",
       "70                                                                                                                                                 Keep you your word, O duke, to give your daughter,-- You yours, Orlando, to receive his daughter.-- Keep you your word, Phoebe, that you 'll marry me, Or else, refusing me, to wed this shepherd.-- Keep your word, Silvius, that you 'll marry her If she refuse me.   \n",
       "71                                                                                                                                                                                                                                                                                                                                                       But, in the beaten way of friendship, what make you at Elsinore?   \n",
       "72                                                                                                                                                                                                                                                                                                                                                                                                      I shall obey you.   \n",
       "73                                                                                                                                                                                                                                                                                                                                                       Will you sterner be Than he that dies and lives by bloody drops?   \n",
       "74                                                                                                                                                                                                                                                                                      I would not hear your enemy say so, Nor shall you do my ear that violence To make it truster of your own report Against yourself.   \n",
       "75                                                                                                                                                                                                                                                                                                                                                      Yet, though I distrust, Discomfort you, my lord, it nothing must.   \n",
       "76                                                                                                                                                                                                                                                                                                                                                                           For your father's remembrance, be at accord.   \n",
       "77                                                                                                                                                 Keep you your word, O duke, to give your daughter,-- You yours, Orlando, to receive his daughter.-- Keep you your word, Phoebe, that you 'll marry me, Or else, refusing me, to wed this shepherd.-- Keep your word, Silvius, that you 'll marry her If she refuse me.   \n",
       "78                                                                                                                                                                                                                                                                                                                                     But I answer you right painted cloth, from whence you have studied your questions.   \n",
       "79                                                                                                                                                                                                                                                                                                                                                                                                           Will you go?   \n",
       "\n",
       "   predicted class true class  \n",
       "0               pl         sg  \n",
       "1               pl         pl  \n",
       "2               sg         sg  \n",
       "3               pl         pl  \n",
       "4               pl         pl  \n",
       "5               sg         sg  \n",
       "6               pl         sg  \n",
       "7               pl         sg  \n",
       "8               pl         pl  \n",
       "9               pl         pl  \n",
       "10              sg         sg  \n",
       "11              pl         pl  \n",
       "12              pl         sg  \n",
       "13              sg         sg  \n",
       "14              sg         sg  \n",
       "15              pl         pl  \n",
       "16              sg         sg  \n",
       "17              pl         pl  \n",
       "18              sg         sg  \n",
       "19              pl         pl  \n",
       "20              sg         sg  \n",
       "21              pl         pl  \n",
       "22              sg         sg  \n",
       "23              pl         pl  \n",
       "24              sg         sg  \n",
       "25              pl         pl  \n",
       "26              sg         pl  \n",
       "27              sg         sg  \n",
       "28              sg         sg  \n",
       "29              pl         pl  \n",
       "30              sg         pl  \n",
       "31              pl         pl  \n",
       "32              sg         sg  \n",
       "33              pl         pl  \n",
       "34              pl         pl  \n",
       "35              sg         sg  \n",
       "36              pl         sg  \n",
       "37              sg         sg  \n",
       "38              pl         pl  \n",
       "39              pl         pl  \n",
       "40              sg         sg  \n",
       "41              pl         pl  \n",
       "42              pl         pl  \n",
       "43              pl         pl  \n",
       "44              pl         pl  \n",
       "45              pl         pl  \n",
       "46              sg         sg  \n",
       "47              pl         pl  \n",
       "48              pl         pl  \n",
       "49              pl         pl  \n",
       "50              sg         sg  \n",
       "51              pl         pl  \n",
       "52              sg         sg  \n",
       "53              pl         sg  \n",
       "54              sg         sg  \n",
       "55              sg         pl  \n",
       "56              pl         pl  \n",
       "57              sg         pl  \n",
       "58              pl         pl  \n",
       "59              sg         sg  \n",
       "60              sg         pl  \n",
       "61              sg         sg  \n",
       "62              pl         pl  \n",
       "63              sg         sg  \n",
       "64              pl         pl  \n",
       "65              pl         pl  \n",
       "66              pl         pl  \n",
       "67              sg         sg  \n",
       "68              pl         sg  \n",
       "69              pl         pl  \n",
       "70              sg         sg  \n",
       "71              sg         pl  \n",
       "72              pl         sg  \n",
       "73              sg         sg  \n",
       "74              sg         sg  \n",
       "75              sg         sg  \n",
       "76              sg         pl  \n",
       "77              sg         sg  \n",
       "78              sg         sg  \n",
       "79              pl         sg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "model_df = make_dataframe(predicted_classes, test_samples)\n",
    "display(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221224f",
   "metadata": {},
   "source": [
    "### DONE UNTIL HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
